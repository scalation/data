{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff80835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "import torch.utils.data as data_utils\n",
    "from functools import partial, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be81ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import mse, mae, smape\n",
    "from models.FFNN import FFNN\n",
    "from models.LSTM_FFNN import LSTM_FFNN\n",
    "from models.LSTM_Seq2Seq import LSTM_Seq2Seq\n",
    "from models.LSTM_Seq2Seq_Att import LSTM_Seq2Seq_Att\n",
    "from data.data_processing import data_processing\n",
    "from data.data_transforms import data_transform_std\n",
    "from data.data_splitting import make_input_output_sequences, train_test_split, shift_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b9be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.032\n",
    "lags = 4\n",
    "h = [4]\n",
    "test_ratio = 0.3\n",
    "file_name = 'datasets\\covid\\OWID_weekly.csv'\n",
    "features = ['date','new_deaths','icu_patients','hosp_patients']\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "patience = 5\n",
    "lstm_hidden_size = 32\n",
    "lstm_layers = 1\n",
    "tf = False\n",
    "FFNN_hidden_1 = 32\n",
    "FFNN_hidden_2 = 64\n",
    "random_seed = 2021\n",
    "tf_ratio = 0.3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "models = ['FFNN', 'LSTM_FFNN', 'LSTM_Seq2Seq', 'LSTM_Seq2Seq_Att']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49e68d72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: FFNN\n",
      "horizon: h1 mse: 322671.061 mae: 408.254 smape: 17.892\n",
      "horizon: h2 mse: 382877.510 mae: 476.075 smape: 20.513\n",
      "horizon: h3 mse: 535571.949 mae: 560.894 smape: 22.476\n",
      "horizon: h4 mse: 729142.080 mae: 616.084 smape: 23.794\n",
      "Average:    mse: 492565.650 mae: 515.327 smape: 21.169\n",
      "\n",
      "Model: LSTM_FFNN\n",
      "horizon: h1 mse: 147808.785 mae: 296.249 smape: 11.446\n",
      "horizon: h2 mse: 229266.735 mae: 395.366 smape: 15.521\n",
      "horizon: h3 mse: 272312.155 mae: 415.892 smape: 16.457\n",
      "horizon: h4 mse: 558367.757 mae: 614.686 smape: 23.456\n",
      "Average:    mse: 301938.858 mae: 430.548 smape: 16.720\n",
      "\n",
      "Model: LSTM_Seq2Seq\n",
      "horizon: h1 mse: 175802.570 mae: 330.441 smape: 13.065\n",
      "horizon: h2 mse: 179776.645 mae: 334.958 smape: 13.300\n",
      "horizon: h3 mse: 195494.321 mae: 366.033 smape: 14.480\n",
      "horizon: h4 mse: 369758.695 mae: 453.123 smape: 17.133\n",
      "Average:    mse: 230208.058 mae: 371.139 smape: 14.494\n",
      "\n",
      "Model: LSTM_Seq2Seq_Att\n",
      "horizon: h1 mse: 168351.011 mae: 340.745 smape: 13.155\n",
      "horizon: h2 mse: 174475.249 mae: 330.567 smape: 12.929\n",
      "horizon: h3 mse: 182671.012 mae: 338.428 smape: 13.513\n",
      "horizon: h4 mse: 253548.453 mae: 421.721 smape: 16.638\n",
      "Average:    mse: 194761.431 mae: 357.865 smape: 14.059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    forecast_matrix = pd.DataFrame(columns = ['date'])\n",
    "    print('Model: '+m)\n",
    "    for horizons in h:\n",
    "        random.seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        data, observed = data_processing(file_name, features)\n",
    "        scalers, df = data_transform_std(data, test_ratio)\n",
    "        x, y = make_input_output_sequences(data.values, lags, horizons, True)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_ratio)\n",
    "        if(m == 'FFNN'):\n",
    "            model = FFNN(FFNN_hidden_1, FFNN_hidden_2, lags, horizons, len(features)-1).to(device)\n",
    "        elif(m == 'LSTM_FFNN'):\n",
    "            model = LSTM_FFNN(lstm_hidden_size, lstm_layers, lags, horizons, len(features)-1).to(device)\n",
    "        elif(m == 'LSTM_Seq2Seq'):\n",
    "            model = LSTM_Seq2Seq(lstm_hidden_size, lstm_layers, lags, horizons, len(features)-1).to(device)\n",
    "        elif(m == 'LSTM_Seq2Seq_Att'):\n",
    "            model = LSTM_Seq2Seq_Att(lstm_hidden_size, lstm_layers, lags, horizons, len(features)-1).to(device)\n",
    "        for w in range(x_test.shape[0]):\n",
    "            n_epochs_stop = patience\n",
    "            epochs_no_improve = 0\n",
    "            early_stop = False\n",
    "            min_val_loss = np.Inf\n",
    "            results = pd.DataFrame(columns = ['date'])\n",
    "            y_test_dates = pd.DataFrame(y_test[0,:,0])\n",
    "            x_train_tensor = torch.from_numpy(np.array(x_train[:,:,1:], dtype=np.float32)).float().to(device)\n",
    "            y_train_tensor = torch.from_numpy(np.array(y_train[:,:,1:], dtype=np.float32)).float().to(device)\n",
    "            x_test_tensor = torch.from_numpy(np.array(x_test[:,:,1:], dtype=np.float32)).float().to(device)\n",
    "            y_test_tensor= torch.from_numpy(np.array(y_test[:,:,1:], dtype=np.float32)).float().to(device)\n",
    "            results['date'] = y_test_dates \n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            train = data_utils.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "            train_loader = data_utils.DataLoader(train, batch_size=batch_size, shuffle=False)\n",
    "            for epoch in range(epochs):\n",
    "                train_losses = []\n",
    "                model.train()\n",
    "                for x_t, y_t in train_loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    y_pred = model(x_t, y_t, tf)\n",
    "                    loss = loss_fn(y_pred, y_t[:,:,0])\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    train_losses.append(loss.item())\n",
    "                train_loss = np.average(train_losses)\n",
    "                if train_loss < min_val_loss:\n",
    "                    epochs_no_improve = 0\n",
    "                    min_val_loss = train_loss\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                if epochs_no_improve == n_epochs_stop:\n",
    "                    break\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                y_test_pred = model(x_test_tensor, y_test_tensor, False)\n",
    "                results['window'+str(w)] = y_test_pred[0,:].cpu().flatten().numpy()\n",
    "            x_train, x_test, y_train, y_test = shift_sequence(x_train, y_train, x_test, y_test, 1, True)\n",
    "            if(w==0):\n",
    "                forecast_matrix = pd.merge(forecast_matrix, results, on=['date'], how='right')\n",
    "            else:\n",
    "                forecast_matrix = pd.merge(forecast_matrix, results, on=['date'], how='outer')\n",
    "        forecast_matrix.head()\n",
    "        date = pd.DataFrame(forecast_matrix['date'])\n",
    "        forecast_matrix.set_index('date', inplace=True)\n",
    "        scaler = scalers['scaler_new_deaths']\n",
    "        forecast_matrix=scaler.inverse_transform(forecast_matrix)\n",
    "        forecast_matrix =pd.DataFrame(forecast_matrix)\n",
    "        forecast_matrix['date'] = date\n",
    "        forecast_matrix.set_index('date', inplace=True)\n",
    "        start = 0\n",
    "        end = 4\n",
    "        weekly_predictions = []\n",
    "        window = 0\n",
    "        for i in range(len(forecast_matrix.columns)-3):\n",
    "            forecast_matrix_temp = forecast_matrix.iloc[start:end]\n",
    "            date = forecast_matrix_temp.tail(1).index.item()\n",
    "            last_row = forecast_matrix_temp.tail(1)\n",
    "            weekly_predictions.append([date, last_row[window][0], last_row[window+1][0],\n",
    "                                       last_row[window+2][0],last_row[window+3][0]])\n",
    "            window = window + 1\n",
    "            start = end\n",
    "            end = end+1\n",
    "        weekly_predictions = pd.DataFrame(weekly_predictions, columns=[ 'date', str('h4_'+m), str('h3_'+m), str('h2_'+m),\n",
    "                                                                      str('h1_'+m)])\n",
    "        observed.reset_index(inplace=True, drop= True)\n",
    "        matrix = reduce(lambda x,y: pd.merge(x,y, on='date'), [observed, weekly_predictions])\n",
    "        matrix.reset_index(inplace=True, drop= True)\n",
    "        metrics = np.empty([4, 3])\n",
    "        for idx, j in enumerate(['h1','h2','h3','h4']):\n",
    "            mse_metric = ('%.3f' %mse(matrix['new_deaths'], matrix[j+'_'+str(m)]))\n",
    "            mae_metric = ('%.3f' %mae(matrix['new_deaths'], matrix[j+'_'+str(m)]))\n",
    "            smape_metric = ('%.3f' %smape(matrix['new_deaths'], matrix[j+'_'+str(m)]))\n",
    "            print('horizon: '+str(j)+' mse: '+ str(mse_metric)+' mae: '+\n",
    "                  str(mae_metric)+' smape: '+ str(smape_metric))\n",
    "            metrics[idx,:] = (mse_metric, mae_metric, smape_metric)\n",
    "        print(\"Average: \"+\"   mse: \"+str(('%.3f' %np.average(metrics[:,0]))) + \n",
    "              \" mae: \"+ str(('%.3f' %np.average(metrics[:,1]))) +\" smape: \"+\n",
    "              str(('%.3f' %np.average(metrics[:,2]))))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9510d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
